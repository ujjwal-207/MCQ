{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4f1be5a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import pandas as pd\n",
    "import traceback"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2648f498",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec9bef20",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install langchain-google-genai\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9651969e",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install google-generativeai\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1a738312",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: langchain-google-genai in c:\\users\\ujjwal\\desktop\\projects\\mcqgen\\env\\lib\\site-packages (2.1.3)\n",
      "Requirement already satisfied: filetype<2.0.0,>=1.2.0 in c:\\users\\ujjwal\\desktop\\projects\\mcqgen\\env\\lib\\site-packages (from langchain-google-genai) (1.2.0)\n",
      "Requirement already satisfied: google-ai-generativelanguage<0.7.0,>=0.6.16 in c:\\users\\ujjwal\\desktop\\projects\\mcqgen\\env\\lib\\site-packages (from langchain-google-genai) (0.6.17)\n",
      "Requirement already satisfied: langchain-core<0.4.0,>=0.3.52 in c:\\users\\ujjwal\\desktop\\projects\\mcqgen\\env\\lib\\site-packages (from langchain-google-genai) (0.3.55)\n",
      "Requirement already satisfied: pydantic<3,>=2 in c:\\users\\ujjwal\\desktop\\projects\\mcqgen\\env\\lib\\site-packages (from langchain-google-genai) (2.11.3)\n",
      "Requirement already satisfied: google-api-core!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1 in c:\\users\\ujjwal\\desktop\\projects\\mcqgen\\env\\lib\\site-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1->google-ai-generativelanguage<0.7.0,>=0.6.16->langchain-google-genai) (2.24.2)\n",
      "Requirement already satisfied: google-auth!=2.24.0,!=2.25.0,<3.0.0,>=2.14.1 in c:\\users\\ujjwal\\desktop\\projects\\mcqgen\\env\\lib\\site-packages (from google-ai-generativelanguage<0.7.0,>=0.6.16->langchain-google-genai) (2.39.0)\n",
      "Requirement already satisfied: proto-plus<2.0.0,>=1.22.3 in c:\\users\\ujjwal\\desktop\\projects\\mcqgen\\env\\lib\\site-packages (from google-ai-generativelanguage<0.7.0,>=0.6.16->langchain-google-genai) (1.26.1)\n",
      "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<7.0.0,>=3.20.2 in c:\\users\\ujjwal\\desktop\\projects\\mcqgen\\env\\lib\\site-packages (from google-ai-generativelanguage<0.7.0,>=0.6.16->langchain-google-genai) (5.29.4)\n",
      "Requirement already satisfied: langsmith<0.4,>=0.1.125 in c:\\users\\ujjwal\\desktop\\projects\\mcqgen\\env\\lib\\site-packages (from langchain-core<0.4.0,>=0.3.52->langchain-google-genai) (0.3.33)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in c:\\users\\ujjwal\\desktop\\projects\\mcqgen\\env\\lib\\site-packages (from langchain-core<0.4.0,>=0.3.52->langchain-google-genai) (9.1.2)\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in c:\\users\\ujjwal\\desktop\\projects\\mcqgen\\env\\lib\\site-packages (from langchain-core<0.4.0,>=0.3.52->langchain-google-genai) (1.33)\n",
      "Requirement already satisfied: PyYAML>=5.3 in c:\\users\\ujjwal\\desktop\\projects\\mcqgen\\env\\lib\\site-packages (from langchain-core<0.4.0,>=0.3.52->langchain-google-genai) (6.0.2)\n",
      "Requirement already satisfied: packaging<25,>=23.2 in c:\\users\\ujjwal\\desktop\\projects\\mcqgen\\env\\lib\\site-packages (from langchain-core<0.4.0,>=0.3.52->langchain-google-genai) (24.2)\n",
      "Requirement already satisfied: typing-extensions>=4.7 in c:\\users\\ujjwal\\desktop\\projects\\mcqgen\\env\\lib\\site-packages (from langchain-core<0.4.0,>=0.3.52->langchain-google-genai) (4.12.2)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in c:\\users\\ujjwal\\desktop\\projects\\mcqgen\\env\\lib\\site-packages (from pydantic<3,>=2->langchain-google-genai) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.33.1 in c:\\users\\ujjwal\\desktop\\projects\\mcqgen\\env\\lib\\site-packages (from pydantic<3,>=2->langchain-google-genai) (2.33.1)\n",
      "Requirement already satisfied: typing-inspection>=0.4.0 in c:\\users\\ujjwal\\desktop\\projects\\mcqgen\\env\\lib\\site-packages (from pydantic<3,>=2->langchain-google-genai) (0.4.0)\n",
      "Requirement already satisfied: googleapis-common-protos<2.0.0,>=1.56.2 in c:\\users\\ujjwal\\desktop\\projects\\mcqgen\\env\\lib\\site-packages (from google-api-core!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1->google-ai-generativelanguage<0.7.0,>=0.6.16->langchain-google-genai) (1.70.0)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.18.0 in c:\\users\\ujjwal\\desktop\\projects\\mcqgen\\env\\lib\\site-packages (from google-api-core!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1->google-ai-generativelanguage<0.7.0,>=0.6.16->langchain-google-genai) (2.32.3)\n",
      "Requirement already satisfied: grpcio<2.0dev,>=1.33.2 in c:\\users\\ujjwal\\desktop\\projects\\mcqgen\\env\\lib\\site-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1->google-ai-generativelanguage<0.7.0,>=0.6.16->langchain-google-genai) (1.72.0rc1)\n",
      "Requirement already satisfied: grpcio-status<2.0.dev0,>=1.33.2 in c:\\users\\ujjwal\\desktop\\projects\\mcqgen\\env\\lib\\site-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1->google-ai-generativelanguage<0.7.0,>=0.6.16->langchain-google-genai) (1.71.0)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in c:\\users\\ujjwal\\desktop\\projects\\mcqgen\\env\\lib\\site-packages (from google-auth!=2.24.0,!=2.25.0,<3.0.0,>=2.14.1->google-ai-generativelanguage<0.7.0,>=0.6.16->langchain-google-genai) (5.5.2)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in c:\\users\\ujjwal\\desktop\\projects\\mcqgen\\env\\lib\\site-packages (from google-auth!=2.24.0,!=2.25.0,<3.0.0,>=2.14.1->google-ai-generativelanguage<0.7.0,>=0.6.16->langchain-google-genai) (0.4.2)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in c:\\users\\ujjwal\\desktop\\projects\\mcqgen\\env\\lib\\site-packages (from google-auth!=2.24.0,!=2.25.0,<3.0.0,>=2.14.1->google-ai-generativelanguage<0.7.0,>=0.6.16->langchain-google-genai) (4.9.1)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in c:\\users\\ujjwal\\desktop\\projects\\mcqgen\\env\\lib\\site-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.4.0,>=0.3.52->langchain-google-genai) (3.0.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in c:\\users\\ujjwal\\desktop\\projects\\mcqgen\\env\\lib\\site-packages (from langsmith<0.4,>=0.1.125->langchain-core<0.4.0,>=0.3.52->langchain-google-genai) (0.28.1)\n",
      "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in c:\\users\\ujjwal\\desktop\\projects\\mcqgen\\env\\lib\\site-packages (from langsmith<0.4,>=0.1.125->langchain-core<0.4.0,>=0.3.52->langchain-google-genai) (3.10.16)\n",
      "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in c:\\users\\ujjwal\\desktop\\projects\\mcqgen\\env\\lib\\site-packages (from langsmith<0.4,>=0.1.125->langchain-core<0.4.0,>=0.3.52->langchain-google-genai) (1.0.0)\n",
      "Requirement already satisfied: zstandard<0.24.0,>=0.23.0 in c:\\users\\ujjwal\\desktop\\projects\\mcqgen\\env\\lib\\site-packages (from langsmith<0.4,>=0.1.125->langchain-core<0.4.0,>=0.3.52->langchain-google-genai) (0.23.0)\n",
      "Requirement already satisfied: anyio in c:\\users\\ujjwal\\desktop\\projects\\mcqgen\\env\\lib\\site-packages (from httpx<1,>=0.23.0->langsmith<0.4,>=0.1.125->langchain-core<0.4.0,>=0.3.52->langchain-google-genai) (4.9.0)\n",
      "Requirement already satisfied: certifi in c:\\users\\ujjwal\\desktop\\projects\\mcqgen\\env\\lib\\site-packages (from httpx<1,>=0.23.0->langsmith<0.4,>=0.1.125->langchain-core<0.4.0,>=0.3.52->langchain-google-genai) (2025.1.31)\n",
      "Requirement already satisfied: httpcore==1.* in c:\\users\\ujjwal\\desktop\\projects\\mcqgen\\env\\lib\\site-packages (from httpx<1,>=0.23.0->langsmith<0.4,>=0.1.125->langchain-core<0.4.0,>=0.3.52->langchain-google-genai) (1.0.8)\n",
      "Requirement already satisfied: idna in c:\\users\\ujjwal\\desktop\\projects\\mcqgen\\env\\lib\\site-packages (from httpx<1,>=0.23.0->langsmith<0.4,>=0.1.125->langchain-core<0.4.0,>=0.3.52->langchain-google-genai) (3.10)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in c:\\users\\ujjwal\\desktop\\projects\\mcqgen\\env\\lib\\site-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith<0.4,>=0.1.125->langchain-core<0.4.0,>=0.3.52->langchain-google-genai) (0.14.0)\n",
      "Requirement already satisfied: pyasn1<0.7.0,>=0.6.1 in c:\\users\\ujjwal\\desktop\\projects\\mcqgen\\env\\lib\\site-packages (from pyasn1-modules>=0.2.1->google-auth!=2.24.0,!=2.25.0,<3.0.0,>=2.14.1->google-ai-generativelanguage<0.7.0,>=0.6.16->langchain-google-genai) (0.6.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\ujjwal\\desktop\\projects\\mcqgen\\env\\lib\\site-packages (from requests<3.0.0,>=2.18.0->google-api-core!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1->google-ai-generativelanguage<0.7.0,>=0.6.16->langchain-google-genai) (3.4.1)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\ujjwal\\desktop\\projects\\mcqgen\\env\\lib\\site-packages (from requests<3.0.0,>=2.18.0->google-api-core!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1->google-ai-generativelanguage<0.7.0,>=0.6.16->langchain-google-genai) (2.4.0)\n",
      "Requirement already satisfied: exceptiongroup>=1.0.2 in c:\\users\\ujjwal\\desktop\\projects\\mcqgen\\env\\lib\\site-packages (from anyio->httpx<1,>=0.23.0->langsmith<0.4,>=0.1.125->langchain-core<0.4.0,>=0.3.52->langchain-google-genai) (1.2.0)\n",
      "Requirement already satisfied: sniffio>=1.1 in c:\\users\\ujjwal\\desktop\\projects\\mcqgen\\env\\lib\\site-packages (from anyio->httpx<1,>=0.23.0->langsmith<0.4,>=0.1.125->langchain-core<0.4.0,>=0.3.52->langchain-google-genai) (1.3.1)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install langchain-google-genai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ce919867",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_google_genai import ChatGoogleGenerativeAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "db65b069",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "669e3856",
   "metadata": {},
   "outputs": [],
   "source": [
    "KEY = os.getenv(\"GOOGLE_GENAI_API_KEY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73f4e8eb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c38b8803",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = ChatGoogleGenerativeAI(model=\"gemini-2.0-flash\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "647c12fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.chains import LLMChain\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e2a85ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install langchain-community"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b98fde04",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_google_genai import GoogleGenerativeAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7d5de3da",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains import LLMChain\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e585933a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import PyPDF2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "265fc42f",
   "metadata": {},
   "outputs": [],
   "source": [
    "TEMPLATE=\"\"\"\n",
    "Text: {text}\n",
    "You are an expert MCQ maker. Given the above text,it is you job to \\\n",
    "create a quiz of {number} multiple choice questions for {subject} students in {tone} tone. \n",
    "Make sure the questions are not repeated and check all the questions to be conforming the text as well.\n",
    "Make sure to format your response like RESPONSE_JSON below and use it as guide .\\\n",
    "Ensure to make {number} MCQs\n",
    "\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbdb6e82",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "02dc04a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "generation_prompt = PromptTemplate(\n",
    "    input_variables=[\"text\",\"number\",\"subject\",\"tone\"],\n",
    "    template=TEMPLATE,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "3520a5be",
   "metadata": {},
   "outputs": [],
   "source": [
    "quiz_chain = generation_prompt | llm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "6b6f8079",
   "metadata": {},
   "outputs": [],
   "source": [
    "TEMPLATE2 = \"\"\"\n",
    "You are an expert english grammarian and writer. Given a Multiple Choice Quiz for {subject} students.\\\n",
    "You need to evaluate the complexity of the question and give a complete analysis of the the quiz. Only use at max 50 words for complexity \n",
    "if the quiz is not at per with the congnitive and analytical abilities of the students,\\\n",
    "update the quiz which needs to be changed and change the tone such that it is more suitable for the students.\\\n",
    "Quiz_MCQs:\n",
    "{quiz}\n",
    "Check form an expert English Writer of the above quiz:\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "4517fdb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "review_prompt = PromptTemplate(input_variables=[\"subject\",\"quiz\"],\n",
    "    template=TEMPLATE2,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "75a3cac5",
   "metadata": {},
   "outputs": [],
   "source": [
    "review_chain = review_prompt | llm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e268bac",
   "metadata": {},
   "source": [
    "we can use like this also review_chain = review_prompt | llm |JsonOutputParser()\n",
    "to get the output in json format "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "d339e752",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.runnables import RunnableLambda, RunnableSequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "50d7269e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.runnables import RunnableParallel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "34b0f955",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains import SequentialChain"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "114624b8",
   "metadata": {},
   "source": [
    "As the sequential chain is decraypted in langchain let i am using simple functions to act like the sequential chain "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87cb623a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "7eddbd2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = \"C:/Users/Ujjwal/Desktop/Projects/mcqgen/data.txt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "11a44744",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'C:/Users/Ujjwal/Desktop/Projects/mcqgen/data.txt'"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file_path  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "7a66b259",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(file_path, \"r\") as file:\n",
    "    TEXT = file.read()\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "2b75b2f1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The term machine learning was coined in 1959 by Arthur Samuel, an IBM employee and pioneer in the field of computer gaming and artificial intelligence.[8][9] The synonym self-teaching computers was also used in this time period.[10][11]\\n\\nAlthough the earliest machine learning model was introduced in the 1950s when Arthur Samuel invented a program that calculated the winning chance in checkers for each side, the history of machine learning roots back to decades of human desire and effort to study human cognitive processes.[12] In 1949, Canadian psychologist Donald Hebb published the book The Organization of Behavior, in which he introduced a theoretical neural structure formed by certain interactions among nerve cells.[13] Hebb\\'s model of neurons interacting with one another set a groundwork for how AIs and machine learning algorithms work under nodes, or artificial neurons used by computers to communicate data.[12] Other researchers who have studied human cognitive systems contributed to the modern machine learning technologies as well, including logician Walter Pitts and Warren McCulloch, who proposed the early mathematical models of neural networks to come up with algorithms that mirror human thought processes.[12]\\n\\nBy the early 1960s, an experimental \"learning machine\" with punched tape memory, called Cybertron, had been developed by Raytheon Company to analyse sonar signals, electrocardiograms, and speech patterns using rudimentary reinforcement learning. It was repetitively \"trained\" by a human operator/teacher to recognise patterns and equipped with a \"goof\" button to cause it to reevaluate incorrect decisions.[14] A representative book on research into machine learning during the 1960s was Nilsson\\'s book on Learning Machines, dealing mostly with machine learning for pattern classification.[15] Interest related to pattern recognition continued into the 1970s, as described by Duda and Hart in 1973.[16] In 1981 a report was given on using teaching strategies so that an artificial neural network learns to recognise 40 characters (26 letters, 10 digits, and 4 special symbols) from a computer terminal.[17]\\n\\nTom M. Mitchell provided a widely quoted, more formal definition of the algorithms studied in the machine learning field: \"A computer program is said to learn from experience E with respect to some class of tasks T and performance measure P if its performance at tasks in T, as measured by P, improves with experience E.\"[18] This definition of the tasks in which machine learning is concerned offers a fundamentally operational definition rather than defining the field in cognitive terms. This follows Alan Turing\\'s proposal in his paper \"Computing Machinery and Intelligence\", in which the question \"Can machines think?\" is replaced with the question \"Can machines do what we (as thinking entities) can do?\".[19]\\n\\nModern-day machine learning has two objectives. One is to classify data based on models which have been developed; the other purpose is to make predictions for future outcomes based on these models. A hypothetical algorithm specific to classifying data may use computer vision of moles coupled with supervised learning in order to train it to classify the cancerous moles. A machine learning algorithm for stock trading may inform the trader of future potential predictions.[20]'"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TEXT "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98aca7cc",
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'JsonOutputParser' from 'langchain.output_parsers.json' (c:\\Users\\Ujjwal\\Desktop\\Projects\\mcqgen\\env\\lib\\site-packages\\langchain\\output_parsers\\json.py)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[3], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mlangchain\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01moutput_parsers\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mjson\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m JsonOutputParser\n",
      "\u001b[1;31mImportError\u001b[0m: cannot import name 'JsonOutputParser' from 'langchain.output_parsers.json' (c:\\Users\\Ujjwal\\Desktop\\Projects\\mcqgen\\env\\lib\\site-packages\\langchain\\output_parsers\\json.py)"
     ]
    }
   ],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b4b1c19",
   "metadata": {},
   "source": [
    "#get_openai_callback() \n",
    "\n",
    "how to setput token usage tracking in langchain\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "05f4c963",
   "metadata": {},
   "outputs": [],
   "source": [
    "import langchain_core.output_parsers\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5d219c2c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "'grep' is not recognized as an internal or external command,\n",
      "operable program or batch file.\n"
     ]
    }
   ],
   "source": [
    "pip list | grep langchain\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2faa69b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.output_parsers import JsonOutputParser\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "7c472106",
   "metadata": {},
   "outputs": [],
   "source": [
    "NUMBER = 3\n",
    "SUBJECT = \"machine learning\"\n",
    "TONE = \"friendly\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "89e4e909",
   "metadata": {},
   "outputs": [],
   "source": [
    "quiz_output = quiz_chain.invoke({\n",
    "    \"text\": TEXT,\n",
    "    \"number\": NUMBER,\n",
    "    \"subject\": SUBJECT,\n",
    "    \"tone\": TONE\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "dff7bfcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "review_output = review_chain.invoke({\n",
    "    \"quiz\": quiz_output.content,\n",
    "    \"subject\": SUBJECT\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d04d965",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "87b60b91",
   "metadata": {},
   "outputs": [],
   "source": [
    "result = {\n",
    "    \"quiz\": quiz_output,\n",
    "    \"review\": review_output\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "6336aea5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "result\n"
     ]
    }
   ],
   "source": [
    "print(\"result\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "6cd5585d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'quiz': AIMessage(content='Okay, here are 3 multiple-choice questions about the history and definition of machine learning, based on the provided text, designed to be friendly and helpful for machine learning students:\\n\\n```json\\n{\\n  \"quiz\": [\\n    {\\n      \"question\": \"Arthur Samuel, who coined the term \\'machine learning,\\' was primarily known for his work in what areas?\",\\n      \"options\": [\\n        \"Theoretical physics and quantum computing.\",\\n        \"Computer gaming and artificial intelligence.\",\\n        \"Linguistics and natural language processing.\",\\n        \"Robotics and automated manufacturing.\"\\n      ],\\n      \"answer\": \"Computer gaming and artificial intelligence.\",\\n      \"explanation\": \"The text states that Arthur Samuel was an IBM employee and a pioneer in computer gaming and artificial intelligence.\"\\n    },\\n    {\\n      \"question\": \"Which of the following best describes Tom M. Mitchell\\'s formal definition of machine learning?\",\\n      \"options\": [\\n        \"A computer\\'s ability to mimic human cognitive processes.\",\\n        \"A computer program\\'s improvement in performance at tasks through experience.\",\\n        \"The development of algorithms that perfectly replicate human thought.\",\\n        \"The creation of self-aware artificial intelligence systems.\"\\n      ],\\n      \"answer\": \"A computer program\\'s improvement in performance at tasks through experience.\",\\n      \"explanation\": \"Tom Mitchell defined machine learning as a program\\'s performance improving with experience on a specific class of tasks, as measured by a performance metric.\"\\n    },\\n    {\\n      \"question\": \"What was the Cybertron, developed by Raytheon Company in the early 1960s, designed to do?\",\\n      \"options\": [\\n        \"Translate between multiple human languages.\",\\n        \"Analyze sonar signals, electrocardiograms, and speech patterns.\",\\n        \"Control industrial robots on an assembly line.\",\\n        \"Predict weather patterns with high accuracy.\"\\n      ],\\n      \"answer\": \"Analyze sonar signals, electrocardiograms, and speech patterns.\",\\n      \"explanation\": \"The text mentions that the Cybertron was designed to analyse sonar signals, electrocardiograms, and speech patterns using rudimentary reinforcement learning.\"\\n    }\\n  ]\\n}\\n```', additional_kwargs={}, response_metadata={'prompt_feedback': {'block_reason': 0, 'safety_ratings': []}, 'finish_reason': 'STOP', 'model_name': 'gemini-2.0-flash', 'safety_ratings': []}, id='run-a5f9b9f3-76d3-4a1e-a00e-0c3ba1746b97-0', usage_metadata={'input_tokens': 757, 'output_tokens': 456, 'total_tokens': 1213, 'input_token_details': {'cache_read': 0}}), 'review': AIMessage(content='Okay, here\\'s my analysis of the machine learning history quiz:\\n\\n**Complexity Analysis:**\\n\\nThe quiz is straightforward, testing recall of specific facts from a text. The language is clear, but the questions primarily assess memorization rather than deeper understanding or application of concepts.\\n\\n**Critique and Improvements:**\\n\\nThe quiz is a good starting point but could be improved to be more engaging and assess higher-order thinking. The current tone is suitable, but let\\'s make the questions a bit more relatable for students.\\n\\nHere\\'s the revised quiz:\\n\\n```json\\n{\\n  \"quiz\": [\\n    {\\n      \"question\": \"Arthur Samuel is considered a pioneer in machine learning. Which of these areas did his work primarily focus on?\",\\n      \"options\": [\\n        \"Quantum computing and theoretical physics (think very small stuff!).\",\\n        \"Creating AI for computer games – like teaching a computer to play chess!\",\\n        \"Helping computers understand human languages.\",\\n        \"Building robots for factories.\"\\n      ],\\n      \"answer\": \"Creating AI for computer games – like teaching a computer to play chess!\",\\n      \"explanation\": \"Arthur Samuel worked at IBM and was a key figure in both computer gaming and artificial intelligence.\"\\n    },\\n    {\\n      \"question\": \"Tom M. Mitchell gave us a formal definition of machine learning. Which of these options gets closest to his idea?\",\\n      \"options\": [\\n        \"Making computers act like humans.\",\\n        \"Helping a computer get better at a task through practice (experience).\",\\n        \"Creating algorithms that perfectly copy how humans think.\",\\n        \"Building robots that are aware of themselves.\"\\n      ],\\n      \"answer\": \"Helping a computer get better at a task through practice (experience).\",\\n      \"explanation\": \"Mitchell\\'s definition focuses on a program improving its performance on a task through experience, using a specific measurement.\"\\n    },\\n    {\\n      \"question\": \"The Cybertron, developed in the 1960s, was designed to analyze what kind of data?\",\\n      \"options\": [\\n        \"Translate languages like Google Translate.\",\\n        \"Analyze signals like sonar, heartbeats (ECGs), and speech.\",\\n        \"Control robots in a factory.\",\\n        \"Predict the weather.\"\\n      ],\\n      \"answer\": \"Analyze signals like sonar, heartbeats (ECGs), and speech.\",\\n      \"explanation\": \"The Cybertron used early reinforcement learning to analyze sonar signals, electrocardiograms, and speech patterns.\"\\n    }\\n  ]\\n}\\n```\\n\\n**Changes Made and Rationale:**\\n\\n*   **Simplified Language:** Replaced more complex phrasing with simpler terms.\\n*   **Relatable Examples:** Added examples (chess, Google Translate) to make the concepts more accessible.\\n*   **Reduced Jargon:** Minimized technical jargon where possible.\\n*   **Added Hints:** Included brief parenthetical hints in some options to guide students.\\n*   **Focus on Understanding:** While still testing recall, the revised questions encourage students to relate the concepts to real-world applications.\\n*   **Tone:** Maintained a friendly and helpful tone.', additional_kwargs={}, response_metadata={'prompt_feedback': {'block_reason': 0, 'safety_ratings': []}, 'finish_reason': 'STOP', 'model_name': 'gemini-2.0-flash', 'safety_ratings': []}, id='run-859666c2-9fc0-4ea4-835d-db7fb68c264a-0', usage_metadata={'input_tokens': 568, 'output_tokens': 660, 'total_tokens': 1228, 'input_token_details': {'cache_read': 0}})}\n"
     ]
    }
   ],
   "source": [
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "97568120",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "Object of type AIMessage is not JSON serializable",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[41], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m result_json \u001b[38;5;241m=\u001b[39m \u001b[43mjson\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdumps\u001b[49m\u001b[43m(\u001b[49m\u001b[43mresult\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindent\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m4\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\Ujjwal\\Desktop\\Projects\\mcqgen\\env\\lib\\json\\__init__.py:238\u001b[0m, in \u001b[0;36mdumps\u001b[1;34m(obj, skipkeys, ensure_ascii, check_circular, allow_nan, cls, indent, separators, default, sort_keys, **kw)\u001b[0m\n\u001b[0;32m    232\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mcls\u001b[39m \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    233\u001b[0m     \u001b[38;5;28mcls\u001b[39m \u001b[38;5;241m=\u001b[39m JSONEncoder\n\u001b[0;32m    234\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mcls\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[0;32m    235\u001b[0m \u001b[43m    \u001b[49m\u001b[43mskipkeys\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mskipkeys\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mensure_ascii\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mensure_ascii\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    236\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcheck_circular\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcheck_circular\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mallow_nan\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mallow_nan\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindent\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mindent\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    237\u001b[0m \u001b[43m    \u001b[49m\u001b[43mseparators\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mseparators\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdefault\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdefault\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msort_keys\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msort_keys\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m--> 238\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkw\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencode\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobj\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\Ujjwal\\Desktop\\Projects\\mcqgen\\env\\lib\\json\\encoder.py:201\u001b[0m, in \u001b[0;36mJSONEncoder.encode\u001b[1;34m(self, o)\u001b[0m\n\u001b[0;32m    199\u001b[0m chunks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39miterencode(o, _one_shot\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m    200\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(chunks, (\u001b[38;5;28mlist\u001b[39m, \u001b[38;5;28mtuple\u001b[39m)):\n\u001b[1;32m--> 201\u001b[0m     chunks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mchunks\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    202\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(chunks)\n",
      "File \u001b[1;32mc:\\Users\\Ujjwal\\Desktop\\Projects\\mcqgen\\env\\lib\\json\\encoder.py:431\u001b[0m, in \u001b[0;36m_make_iterencode.<locals>._iterencode\u001b[1;34m(o, _current_indent_level)\u001b[0m\n\u001b[0;32m    429\u001b[0m     \u001b[38;5;28;01myield from\u001b[39;00m _iterencode_list(o, _current_indent_level)\n\u001b[0;32m    430\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(o, \u001b[38;5;28mdict\u001b[39m):\n\u001b[1;32m--> 431\u001b[0m     \u001b[38;5;28;01myield from\u001b[39;00m _iterencode_dict(o, _current_indent_level)\n\u001b[0;32m    432\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    433\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m markers \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Users\\Ujjwal\\Desktop\\Projects\\mcqgen\\env\\lib\\json\\encoder.py:405\u001b[0m, in \u001b[0;36m_make_iterencode.<locals>._iterencode_dict\u001b[1;34m(dct, _current_indent_level)\u001b[0m\n\u001b[0;32m    403\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    404\u001b[0m             chunks \u001b[38;5;241m=\u001b[39m _iterencode(value, _current_indent_level)\n\u001b[1;32m--> 405\u001b[0m         \u001b[38;5;28;01myield from\u001b[39;00m chunks\n\u001b[0;32m    406\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m newline_indent \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    407\u001b[0m     _current_indent_level \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n",
      "File \u001b[1;32mc:\\Users\\Ujjwal\\Desktop\\Projects\\mcqgen\\env\\lib\\json\\encoder.py:438\u001b[0m, in \u001b[0;36m_make_iterencode.<locals>._iterencode\u001b[1;34m(o, _current_indent_level)\u001b[0m\n\u001b[0;32m    436\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCircular reference detected\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    437\u001b[0m     markers[markerid] \u001b[38;5;241m=\u001b[39m o\n\u001b[1;32m--> 438\u001b[0m o \u001b[38;5;241m=\u001b[39m \u001b[43m_default\u001b[49m\u001b[43m(\u001b[49m\u001b[43mo\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    439\u001b[0m \u001b[38;5;28;01myield from\u001b[39;00m _iterencode(o, _current_indent_level)\n\u001b[0;32m    440\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m markers \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Users\\Ujjwal\\Desktop\\Projects\\mcqgen\\env\\lib\\json\\encoder.py:179\u001b[0m, in \u001b[0;36mJSONEncoder.default\u001b[1;34m(self, o)\u001b[0m\n\u001b[0;32m    160\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mdefault\u001b[39m(\u001b[38;5;28mself\u001b[39m, o):\n\u001b[0;32m    161\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Implement this method in a subclass such that it returns\u001b[39;00m\n\u001b[0;32m    162\u001b[0m \u001b[38;5;124;03m    a serializable object for ``o``, or calls the base implementation\u001b[39;00m\n\u001b[0;32m    163\u001b[0m \u001b[38;5;124;03m    (to raise a ``TypeError``).\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    177\u001b[0m \n\u001b[0;32m    178\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 179\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mObject of type \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mo\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m    180\u001b[0m                     \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mis not JSON serializable\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[1;31mTypeError\u001b[0m: Object of type AIMessage is not JSON serializable"
     ]
    }
   ],
   "source": [
    "result_json = json.dumps(result, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc719c58",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
